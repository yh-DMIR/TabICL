#!/usr/bin/env bash
set -e

PYTHON=python
SCRIPT=benchmark_tabicl_dynamic.py

DATA_ROOT=limix
OUT_ROOT=results/v1.1_parallel_3+3+2
mkdir -p "${OUT_ROOT}"

export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1

CKPT_VERSION=tabicl-classifier-v1.1-0506.ckpt
LOCAL_CKPT_PATH="./tabicl-classifier-v1.1-0506.ckpt"

COMMON_ARGS="
  --device cuda:0
  --batch-size 4
  --n-estimators 32
  --norm-methods none,power
  --feat-shuffle latin
  --softmax-temp 0.9
  --checkpoint-version ${CKPT_VERSION}
  --model-path ${LOCAL_CKPT_PATH}
  --verbose
"

echo "ðŸš€ Launching TALENT(0,1,2) + TabZilla(3,4,5) + OpenML-CC18(6,7) in parallel..."

# TALENT -> GPU 0,1,2
(
  ${PYTHON} ${SCRIPT} \
    --root "${DATA_ROOT}/talent_csv" \
    --out-dir "${OUT_ROOT}/talent" \
    --all-out "${OUT_ROOT}/tabicl_talent.ALL.csv" \
    --summary-txt "${OUT_ROOT}/tabicl_talent.summary.txt" \
    --workers 3 \
    --gpus 0,1,2 \
    ${COMMON_ARGS}
) &

# TabZilla -> GPU 3,4,5
(
  ${PYTHON} ${SCRIPT} \
    --root "${DATA_ROOT}/tabzilla_csv" \
    --out-dir "${OUT_ROOT}/tabzilla" \
    --all-out "${OUT_ROOT}/tabicl_tabzilla.ALL.csv" \
    --summary-txt "${OUT_ROOT}/tabicl_tabzilla.summary.txt" \
    --workers 3 \
    --gpus 3,4,5 \
    ${COMMON_ARGS}
) &

# OpenML-CC18 -> GPU 6,7
(
  ${PYTHON} ${SCRIPT} \
    --root "${DATA_ROOT}/openml_cc18_csv" \
    --out-dir "${OUT_ROOT}/openml_cc18" \
    --all-out "${OUT_ROOT}/tabicl_openml_cc18.ALL.csv" \
    --summary-txt "${OUT_ROOT}/tabicl_openml_cc18.summary.txt" \
    --workers 2 \
    --gpus 6,7 \
    ${COMMON_ARGS}
) &

wait
echo "âœ… All datasets finished."
echo "Results saved in: ${OUT_ROOT}"
